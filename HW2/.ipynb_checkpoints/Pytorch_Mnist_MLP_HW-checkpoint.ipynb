{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "881b9d71",
   "metadata": {
    "id": "881b9d71"
   },
   "source": [
    "# 作業目標:\n",
    "## 利用手寫辨識資料說明MLP 中, 神經網路層的多寡跟預測結果的差異"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7c46bb",
   "metadata": {
    "id": "0a7c46bb"
   },
   "source": [
    "# 作業重點:\n",
    "## 請新增兩層MLP與三層MLP看看最後預測結果與一層的MLP是否有差異\n",
    "## 請詳細說明修改的程式碼位置與你覺得為什麼會有差異?\n",
    "## 請注意!!! 每一個block code都一定要在自己本機執行過後再上傳到雲端學院與github\n",
    "## 請注意!!! ipynb檔名:Pytorch_Mnist_MLP_HW_學號.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d7b78d",
   "metadata": {
    "id": "55d7b78d"
   },
   "source": [
    "參考程式: https://github.com/iam-mhaseeb/Multi-Layer-Perceptron-MNIST-with-PyTorch/blob/master/mnist_mlp_exercise.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ed8cf83",
   "metadata": {
    "id": "8ed8cf83"
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c2d15a1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2c2d15a1",
    "outputId": "aee710da-9285-49b8-fc13-405a3dd82e50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:00<00:00, 228642747.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 39651618.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 67469478.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 23783431.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# number of subprocesses to use for data loading\n",
    "num_workers = 0\n",
    "# how many samples per batch to load\n",
    "batch_size = 20\n",
    "\n",
    "# convert data to torch.FloatTensor\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "# choose the training and test datasets\n",
    "train_data = datasets.MNIST(root='data', train=True,\n",
    "                                   download=True, transform=transform)\n",
    "test_data = datasets.MNIST(root='data', train=False,\n",
    "                                  download=True, transform=transform)\n",
    "\n",
    "# prepare data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
    "    num_workers=num_workers)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
    "    num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf0ede2c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "id": "bf0ede2c",
    "outputId": "e7973335-e64d-4536-eed1-67515d7ed825"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2500x400 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "    \n",
    "# obtain one batch of training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.__next__()\n",
    "images = images.numpy()\n",
    "\n",
    "# plot the images in the batch, along with the corresponding labels\n",
    "fig = plt.figure(figsize=(25, 4))\n",
    "for idx in np.arange(20):\n",
    "    ax = fig.add_subplot(2, int(20/2), idx+1, xticks=[], yticks=[])\n",
    "    ax.imshow(np.squeeze(images[idx]), cmap='gray')\n",
    "    # print out the correct label for each image\n",
    "    # .item() gets the value contained in a Tensor\n",
    "    ax.set_title(str(labels[idx].item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9fe8bd",
   "metadata": {
    "id": "ec9fe8bd"
   },
   "source": [
    "## Define the Network Architecture\n",
    "    這個MLP架構將每個影像的784張量(pixel)視為輸入，並生成一個長度為10（class number）的張量。這個例子使用了兩個hidden layer和dropout 來避免overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81521215",
   "metadata": {
    "id": "81521215"
   },
   "source": [
    "單層 MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26ea6375",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "26ea6375",
    "outputId": "679bce99-bd02-42ba-ff0a-6630e4fcccc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (fc3): Linear(in_features=512, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "## Define the NN architecture 單層 mlp\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 512)\n",
    "        # linear layer (n_hidden -> hidden_2)\n",
    "        self.fc2 = nn.Linear(512, 512)\n",
    "        # linear layer (n_hidden -> 10)\n",
    "        self.fc3 = nn.Linear(512, 10)\n",
    "        # dropout layer (p=0.2)\n",
    "        # dropout prevents overfitting of data\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # flatten image input\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        # add hidden layer, with relu activation function \n",
    "        x = F.relu(self.fc1(x))\n",
    "        return x\n",
    "\n",
    "# initialize the NN\n",
    "model = Net()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ebf7b4",
   "metadata": {
    "id": "d6ebf7b4"
   },
   "source": [
    "二層 MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1812726f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1812726f",
    "outputId": "3a077d67-2cc1-43a1-e3dd-5d4ff21c8cb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net2Layers(\n",
      "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (fc3): Linear(in_features=512, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net2Layers(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net2Layers, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 512)  # 第一個全連接層，輸入維度為 28 * 28，輸出維度為 512\n",
    "        self.fc2 = nn.Linear(512, 512) # 第二個全連接層，輸入維度為 512，輸出維度為 512\n",
    "        self.fc3 = nn.Linear(512, 10) # 第三個全連接層，輸入維度為 512，輸出維度為 10\n",
    "        self.dropout = nn.Dropout(0.2)  # Dropout 層，機率為 0.2，用於防止過擬合\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28) # 將輸入的圖像展平成向量\n",
    "        # 兩層\n",
    "        x = F.relu(self.fc1(x)) # 使用 ReLU 激活函數的第一個隱藏層\n",
    "        x = F.relu(self.fc2(x)) # 使用 ReLU 激活函數的第二個隱藏層\n",
    "        return x\n",
    "    \n",
    "# 初始化模型\n",
    "model_2layers = Net2Layers()\n",
    "print(model_2layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4bd54a",
   "metadata": {
    "id": "9b4bd54a"
   },
   "source": [
    "三層 MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "886bc761",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "886bc761",
    "outputId": "0dcb6bae-436f-4abe-e59f-bd24617147b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net2Layers(\n",
      "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (fc3): Linear(in_features=512, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net3Layers(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net3Layers, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 512)\n",
    "        self.fc2 = nn.Linear(512, 512)\n",
    "        self.fc3 = nn.Linear(512, 512)\n",
    "        self.fc4 = nn.Linear(512, 10)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        # 三層\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        return x\n",
    "    \n",
    "# 初始化模型\n",
    "model_3layers = Net3Layers()\n",
    "print(model_2layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1dc7c67",
   "metadata": {
    "id": "e1dc7c67"
   },
   "source": [
    "## 定義loss function and optimizer (這裡選擇SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86653f93",
   "metadata": {
    "id": "86653f93"
   },
   "outputs": [],
   "source": [
    "\n",
    "## Specify loss and optimization functions\n",
    "\n",
    "# specify loss function 設定損失函數\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# specify optimizer 設定分別的優化器\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "optimizer_2layers = torch.optim.SGD(model_2layers.parameters(), lr=0.01)\n",
    "optimizer_3layers = torch.optim.SGD(model_3layers.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663c13fa",
   "metadata": {
    "id": "663c13fa"
   },
   "source": [
    "## Training Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207bee93",
   "metadata": {
    "id": "207bee93"
   },
   "source": [
    "單層 MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "079946c0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "079946c0",
    "outputId": "f4eada31-c738-49f4-cebb-a3dde954fee7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.793856\n",
      "Epoch: 2 \tTraining Loss: 0.411733\n",
      "Epoch: 3 \tTraining Loss: 0.370092\n",
      "Epoch: 4 \tTraining Loss: 0.349000\n",
      "Epoch: 5 \tTraining Loss: 0.335553\n",
      "Epoch: 6 \tTraining Loss: 0.325974\n",
      "Epoch: 7 \tTraining Loss: 0.318684\n",
      "Epoch: 8 \tTraining Loss: 0.312884\n",
      "Epoch: 9 \tTraining Loss: 0.308120\n",
      "Epoch: 10 \tTraining Loss: 0.304112\n"
     ]
    }
   ],
   "source": [
    "# number of epochs to train the model\n",
    "n_epochs = 10  # suggest training between 20-50 epochs\n",
    "\n",
    "model.train() # prep model for training\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # monitor training loss\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    for data, target in train_loader:\n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "        # backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        # update running training loss\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "        \n",
    "    # print training statistics \n",
    "    # calculate average loss over an epoch\n",
    "    train_loss = train_loss/len(train_loader.dataset)\n",
    "\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(\n",
    "        epoch+1, \n",
    "        train_loss\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d87eac",
   "metadata": {
    "id": "26d87eac"
   },
   "source": [
    "二層 MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f465b246",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f465b246",
    "outputId": "f537495a-d0fb-4cd3-88a8-5752a18c7c69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.133855\n",
      "Epoch: 2 \tTraining Loss: 0.124534\n",
      "Epoch: 3 \tTraining Loss: 0.116290\n",
      "Epoch: 4 \tTraining Loss: 0.108952\n",
      "Epoch: 5 \tTraining Loss: 0.102383\n",
      "Epoch: 6 \tTraining Loss: 0.096483\n",
      "Epoch: 7 \tTraining Loss: 0.091151\n",
      "Epoch: 8 \tTraining Loss: 0.086316\n",
      "Epoch: 9 \tTraining Loss: 0.081898\n",
      "Epoch: 10 \tTraining Loss: 0.077854\n"
     ]
    }
   ],
   "source": [
    "# number of epochs to train the model\n",
    "n_epochs = 10  # suggest training between 20-50 epochs\n",
    "\n",
    "model_2layers.train() # prep model for training\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # monitor training loss\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    for data, target in train_loader:\n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer_2layers.zero_grad()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model_2layers(data)\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "        # backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # perform a single optimization step (parameter update)\n",
    "        optimizer_2layers.step()\n",
    "        # update running training loss\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "        \n",
    "    # print training statistics \n",
    "    # calculate average loss over an epoch\n",
    "    train_loss = train_loss/len(train_loader.dataset)\n",
    "\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(\n",
    "        epoch+1, \n",
    "        train_loss\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce4e5ca",
   "metadata": {
    "id": "1ce4e5ca"
   },
   "source": [
    "三層 MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ede9d518",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ede9d518",
    "outputId": "4da7cfaf-25e4-4b13-d059-7c713a5da7cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.696493\n",
      "Epoch: 2 \tTraining Loss: 0.689045\n",
      "Epoch: 3 \tTraining Loss: 0.682583\n",
      "Epoch: 4 \tTraining Loss: 0.676916\n",
      "Epoch: 5 \tTraining Loss: 0.671888\n",
      "Epoch: 6 \tTraining Loss: 0.667458\n",
      "Epoch: 7 \tTraining Loss: 0.663457\n",
      "Epoch: 8 \tTraining Loss: 0.659848\n",
      "Epoch: 9 \tTraining Loss: 0.656585\n",
      "Epoch: 10 \tTraining Loss: 0.653603\n"
     ]
    }
   ],
   "source": [
    "# number of epochs to train the model\n",
    "n_epochs = 10  # suggest training between 20-50 epochs\n",
    "\n",
    "model_3layers.train() # prep model for training\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # monitor training loss\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    for data, target in train_loader:\n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer_3layers.zero_grad()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model_3layers(data)\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "        # backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # perform a single optimization step (parameter update)\n",
    "        optimizer_3layers.step()\n",
    "        # update running training loss\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "        \n",
    "    # print training statistics \n",
    "    # calculate average loss over an epoch\n",
    "    train_loss = train_loss/len(train_loader.dataset)\n",
    "\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(\n",
    "        epoch+1, \n",
    "        train_loss\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2d8c8c",
   "metadata": {
    "id": "bd2d8c8c"
   },
   "source": [
    "## Testing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7bcb7c9a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7bcb7c9a",
    "outputId": "db44b252-c47c-4901-cc71-f97d76684030"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.292885\n",
      "\n",
      "Test Accuracy of 一層     0: 98% (962/980)\n",
      "Test Accuracy of 一層     1: 97% (1105/1135)\n",
      "Test Accuracy of 一層     2: 87% (903/1032)\n",
      "Test Accuracy of 一層     3: 90% (911/1010)\n",
      "Test Accuracy of 一層     4: 92% (909/982)\n",
      "Test Accuracy of 一層     5: 87% (779/892)\n",
      "Test Accuracy of 一層     6: 94% (906/958)\n",
      "Test Accuracy of 一層     7: 91% (937/1028)\n",
      "Test Accuracy of 一層     8: 88% (860/974)\n",
      "Test Accuracy of 一層     9: 89% (908/1009)\n",
      "\n",
      "Test Accuracy (Overall): 91% (9180/10000)\n"
     ]
    }
   ],
   "source": [
    "# initialize lists to monitor test loss and accuracy\n",
    "test_loss = 0.0\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "\n",
    "model.eval() # prep model for *evaluation*\n",
    "\n",
    "for data, target in test_loader:\n",
    "    # forward pass: compute predicted outputs by passing inputs to the model\n",
    "    output = model(data)\n",
    "    # calculate the loss\n",
    "    loss = criterion(output, target)\n",
    "    # update test loss \n",
    "    test_loss += loss.item()*data.size(0)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, pred = torch.max(output, 1)\n",
    "    # compare predictions to true label\n",
    "    correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n",
    "    # calculate test accuracy for each object class\n",
    "    for i in range(batch_size):\n",
    "        label = target.data[i]\n",
    "        class_correct[label] += correct[i].item()\n",
    "        class_total[label] += 1\n",
    "\n",
    "# calculate and print avg test loss\n",
    "test_loss = test_loss/len(test_loader.dataset)\n",
    "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "for i in range(10):\n",
    "    if class_total[i] > 0:\n",
    "        print('Test Accuracy of 一層 %5s: %2d%% (%2d/%2d)' % (\n",
    "            str(i), 100 * class_correct[i] / class_total[i],\n",
    "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "    else:\n",
    "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
    "\n",
    "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
    "    100. * np.sum(class_correct) / np.sum(class_total),\n",
    "    np.sum(class_correct), np.sum(class_total)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d839b35c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d839b35c",
    "outputId": "26093360-ded1-4f1c-a468-cb0d549ea717"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.093750\n",
      "\n",
      "Test Accuracy of 二層     0: 98% (970/980)\n",
      "Test Accuracy of 二層     1: 98% (1121/1135)\n",
      "Test Accuracy of 二層     2: 97% (1006/1032)\n",
      "Test Accuracy of 二層     3: 97% (983/1010)\n",
      "Test Accuracy of 二層     4: 97% (954/982)\n",
      "Test Accuracy of 二層     5: 97% (870/892)\n",
      "Test Accuracy of 二層     6: 96% (925/958)\n",
      "Test Accuracy of 二層     7: 96% (991/1028)\n",
      "Test Accuracy of 二層     8: 96% (937/974)\n",
      "Test Accuracy of 二層     9: 95% (968/1009)\n",
      "\n",
      "Test Accuracy (Overall): 97% (9725/10000)\n"
     ]
    }
   ],
   "source": [
    "# initialize lists to monitor test loss and accuracy\n",
    "test_loss = 0.0\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "\n",
    "model_2layers.eval() # prep model for *evaluation*\n",
    "\n",
    "for data, target in test_loader:\n",
    "    # forward pass: compute predicted outputs by passing inputs to the model\n",
    "    output = model_2layers(data)\n",
    "    # calculate the loss\n",
    "    loss = criterion(output, target)\n",
    "    # update test loss \n",
    "    test_loss += loss.item()*data.size(0)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, pred = torch.max(output, 1)\n",
    "    # compare predictions to true label\n",
    "    correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n",
    "    # calculate test accuracy for each object class\n",
    "    for i in range(batch_size):\n",
    "        label = target.data[i]\n",
    "        class_correct[label] += correct[i].item()\n",
    "        class_total[label] += 1\n",
    "\n",
    "# calculate and print avg test loss\n",
    "test_loss = test_loss/len(test_loader.dataset)\n",
    "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "for i in range(10):\n",
    "    if class_total[i] > 0:\n",
    "        print('Test Accuracy of 二層 %5s: %2d%% (%2d/%2d)' % (\n",
    "            str(i), 100 * class_correct[i] / class_total[i],\n",
    "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "    else:\n",
    "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
    "\n",
    "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
    "    100. * np.sum(class_correct) / np.sum(class_total),\n",
    "    np.sum(class_correct), np.sum(class_total)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "sITTLWJtelkK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sITTLWJtelkK",
    "outputId": "d1f2be98-67fc-40e7-9095-2148a5f5bf31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.701614\n",
      "\n",
      "Test Accuracy of 三層     0: 99% (971/980)\n",
      "Test Accuracy of 三層     1: 99% (1127/1135)\n",
      "Test Accuracy of 三層     2: 97% (1011/1032)\n",
      "Test Accuracy of 三層     3: 98% (991/1010)\n",
      "Test Accuracy of 三層     4: 99% (973/982)\n",
      "Test Accuracy of 三層     5: 97% (873/892)\n",
      "Test Accuracy of 三層     6: 96% (929/958)\n",
      "Test Accuracy of 三層     7: 97% (1003/1028)\n",
      "Test Accuracy of 三層     8: 97% (947/974)\n",
      "Test Accuracy of 三層     9:  0% ( 0/1009)\n",
      "\n",
      "Test Accuracy (Overall): 88% (8825/10000)\n"
     ]
    }
   ],
   "source": [
    "# initialize lists to monitor test loss and accuracy\n",
    "test_loss = 0.0\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "\n",
    "model_3layers.eval() # prep model for *evaluation*\n",
    "\n",
    "for data, target in test_loader:\n",
    "    # forward pass: compute predicted outputs by passing inputs to the model\n",
    "    output = model_3layers(data)\n",
    "    # calculate the loss\n",
    "    loss = criterion(output, target)\n",
    "    # update test loss \n",
    "    test_loss += loss.item()*data.size(0)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, pred = torch.max(output, 1)\n",
    "    # compare predictions to true label\n",
    "    correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n",
    "    # calculate test accuracy for each object class\n",
    "    for i in range(batch_size):\n",
    "        label = target.data[i]\n",
    "        class_correct[label] += correct[i].item()\n",
    "        class_total[label] += 1\n",
    "\n",
    "# calculate and print avg test loss\n",
    "test_loss = test_loss/len(test_loader.dataset)\n",
    "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "for i in range(10):\n",
    "    if class_total[i] > 0:\n",
    "        print('Test Accuracy of 三層 %5s: %2d%% (%2d/%2d)' % (\n",
    "            str(i), 100 * class_correct[i] / class_total[i],\n",
    "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "    else:\n",
    "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
    "\n",
    "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
    "    100. * np.sum(class_correct) / np.sum(class_total),\n",
    "    np.sum(class_correct), np.sum(class_total)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OKZgL1Hzjiml",
   "metadata": {
    "id": "OKZgL1Hzjiml"
   },
   "source": [
    "## **分析比較二層三層MLP的差異**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "L8dUDs0AiXUk",
   "metadata": {
    "id": "L8dUDs0AiXUk"
   },
   "source": [
    "## **損失函數（Loss Function）結果**\n",
    "### **一層 MLP**\n",
    "\n",
    "Epoch: 1 \tTraining Loss: 0.793856\n",
    "\n",
    "Epoch: 2 \tTraining Loss: 0.411733\n",
    "\n",
    "Epoch: 3 \tTraining Loss: 0.370092\n",
    "\n",
    "Epoch: 4 \tTraining Loss: 0.349000\n",
    "\n",
    "Epoch: 5 \tTraining Loss: 0.335553\n",
    "\n",
    "Epoch: 6 \tTraining Loss: 0.325974\n",
    "\n",
    "Epoch: 7 \tTraining Loss: 0.318684\n",
    "\n",
    "Epoch: 8 \tTraining Loss: 0.312884\n",
    "\n",
    "Epoch: 9 \tTraining Loss: 0.308120\n",
    "\n",
    "Epoch: 10 \tTraining Loss: 0.304112\n",
    "\n",
    "###  **二層 MLP**\n",
    "Epoch: 1 \tTraining Loss: 0.133855\n",
    "\n",
    "\n",
    "Epoch: 2 \tTraining Loss: 0.124534\n",
    "\n",
    "Epoch: 3 \tTraining Loss: 0.116290\n",
    "\n",
    "Epoch: 4 \tTraining Loss: 0.108952\n",
    "\n",
    "Epoch: 5 \tTraining Loss: 0.102383\n",
    "\n",
    "Epoch: 6 \tTraining Loss: 0.096483\n",
    "\n",
    "Epoch: 7 \tTraining Loss: 0.091151\n",
    "\n",
    "Epoch: 8 \tTraining Loss: 0.086316\n",
    "\n",
    "Epoch: 9 \tTraining Loss: 0.081898\n",
    "\n",
    "Epoch: 10 \tTraining Loss: 0.077854\n",
    "\n",
    "### **三層 MLP**\n",
    "\n",
    "Epoch: 1 \tTraining Loss: 0.696493\n",
    "\n",
    "Epoch: 2 \tTraining Loss: 0.689045\n",
    "\n",
    "Epoch: 3 \tTraining Loss: 0.682583\n",
    "\n",
    "Epoch: 4 \tTraining Loss: 0.676916\n",
    "\n",
    "Epoch: 5 \tTraining Loss: 0.671888\n",
    "\n",
    "Epoch: 6 \tTraining Loss: 0.667458\n",
    "\n",
    "Epoch: 7 \tTraining Loss: 0.663457\n",
    "\n",
    "Epoch: 8 \tTraining Loss: 0.659848\n",
    "\n",
    "Epoch: 9 \tTraining Loss: 0.656585\n",
    "\n",
    "Epoch: 10 \tTraining Loss: 0.653603\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZZwkBdtUkYrb",
   "metadata": {
    "id": "ZZwkBdtUkYrb"
   },
   "source": [
    "分析不同層的MLP模型的損失函數（Loss Function）結果：\n",
    "\n",
    "*   一層MLP的訓練損失從初始值0.793856下降到最後一輪的0.304112，這表示模型在訓練過程中逐漸學習到更好的參數，對訓練數據的擬合效果不斷改善。\n",
    "\n",
    "*   二層MLP的訓練損失相對較小，從初始值0.133855下降到最後一輪的0.077854。相較於一層MLP，二層MLP在相同的訓練週期內有更低的損失，表示它更有效地學習了訓練數據的特徵。\n",
    "\n",
    "*   三層MLP的訓練損失相對較高，從初始值0.696493下降到最後一輪的0.653603，相較於一層和二層MLP，三層MLP的訓練損失較高，說明在當前的架構和參數設置下，它沒有很好地擬合訓練數據。\n",
    "\n",
    "總結來說，**二層MLP在訓練過程中表現最好**，其訓練損失最小，代表它能更好地擬合訓練數據。一層MLP次之，訓練損失略高於二層MLP，但仍然具有較好的擬合能力，但三層MLP在訓練數據上表現很差，訓練損失較高，可能需要進一步調整架構或超參數來改善其性能。\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vOYe6ro3kikl",
   "metadata": {
    "id": "vOYe6ro3kikl"
   },
   "source": [
    "### **一層MLP**\n",
    "Test Loss: 0.292885\n",
    "\n",
    "Test Accuracy of 一層     0: 98% (962/980)\n",
    "\n",
    "Test Accuracy of 一層     1: 97% (1105/1135)\n",
    "\n",
    "Test Accuracy of 一層     2: 87% (903/1032)\n",
    "\n",
    "Test Accuracy of 一層     3: 90% (911/1010)\n",
    "\n",
    "Test Accuracy of 一層     4: 92% (909/982)\n",
    "\n",
    "Test Accuracy of 一層     5: 87% (779/892)\n",
    "\n",
    "Test Accuracy of 一層     6: 94% (906/958)\n",
    "\n",
    "Test Accuracy of 一層     7: 91% (937/1028)\n",
    "\n",
    "Test Accuracy of 一層     8: 88% (860/974)\n",
    "\n",
    "Test Accuracy of 一層     9: 89% (908/1009)\n",
    "\n",
    "Test Accuracy (Overall): **91%** (9180/10000)\n",
    "\n",
    "### **二層MLP**\n",
    "Test Loss: 0.093750\n",
    "\n",
    "Test Accuracy of 二層     0: 98% (970/980)\n",
    "\n",
    "Test Accuracy of 二層     1: 98% (1121/1135)\n",
    "\n",
    "Test Accuracy of 二層     2: 97% (1006/1032)\n",
    "\n",
    "Test Accuracy of 二層     3: 97% (983/1010)\n",
    "\n",
    "Test Accuracy of 二層     4: 97% (954/982)\n",
    "\n",
    "Test Accuracy of 二層     5: 97% (870/892)\n",
    "\n",
    "Test Accuracy of 二層     6: 96% (925/958)\n",
    "\n",
    "Test Accuracy of 二層     7: 96% (991/1028)\n",
    "\n",
    "Test Accuracy of 二層     8: 96% (937/974)\n",
    "\n",
    "Test Accuracy of 二層     9: 95% (968/1009)\n",
    "\n",
    "Test Accuracy (Overall): **97%** (9725/10000)\n",
    "### **三層MLP**\n",
    "Test Loss: 0.701614\n",
    "\n",
    "Test Accuracy of 三層     0: 99% (971/980)\n",
    "\n",
    "Test Accuracy of 三層     1: 99% (1127/1135)\n",
    "\n",
    "Test Accuracy of 三層     2: 97% (1011/1032)\n",
    "\n",
    "Test Accuracy of 三層     3: 98% (991/1010)\n",
    "\n",
    "Test Accuracy of 三層     4: 99% (973/982)\n",
    "\n",
    "Test Accuracy of 三層     5: 97% (873/892)\n",
    "\n",
    "Test Accuracy of 三層     6: 96% (929/958)\n",
    "\n",
    "Test Accuracy of 三層     7: 97% (1003/1028)\n",
    "\n",
    "Test Accuracy of 三層     8: 97% (947/974)\n",
    "\n",
    "Test Accuracy of 三層     9:  0% ( 0/1009)\n",
    "\n",
    "Test Accuracy (Overall): **88%** (8825/10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QcaqooDRdfCX",
   "metadata": {
    "id": "QcaqooDRdfCX"
   },
   "source": [
    "根據測試模型的結果，我們可以得出以下分析：\n",
    "\n",
    "* **一層 MLP：**\n",
    "在測試集上的平均準確度為 91%。\n",
    "\n",
    "  除了數字 9 的準確度稍低（89%），其他數字的準確度都相對較高，介於 87% 到 98% 之間。\n",
    "整體而言，一層 MLP 在測試集上表現良好，但對於數字 9 的辨識能力較弱。\n",
    "* **二層 MLP：**\n",
    "在測試集上的平均準確度為 97%。\n",
    "\n",
    "  所有數字的準確度都相對較高，介於 95% 到 99% 之間。\n",
    "二層 MLP 在測試集上表現優秀，各數字的辨識能力都相對較強。\n",
    "* **三層 MLP：**\n",
    "在測試集上的平均準確度為 88%。\n",
    "\n",
    "  大多數數字的準確度都相對較高，介於 96% 到 99% 之間，除了數字 9 的準確度為 0%。\n",
    "    三層 MLP 在測試集上的整體表現較差，尤其是對於數字 9 的辨識能力幾乎為零。\n",
    "\n",
    "總結來說，，二層 MLP 在測試集上取得了最高的準確度，顯示其較好的模型性能。一層 MLP 也有相對不錯的準確度，但對於數字 9 的辨識能力稍差。三層 MLP 在除了數字 9 外的大多數情況下表現良好，但對於**數字 9 的辨識能力非常差為0%**。因此，從 **準確度** 和 **模型性能** 的角度來看，**採用二層 MLP 是最佳的選擇**。"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
